{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad9fe964",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Install dependencies (run this only once)\n",
    "# !pip install aif360 scikit-learn seaborn matplotlib\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from aif360.datasets import CompasDataset\n",
    "from aif360.metrics import BinaryLabelDatasetMetric, ClassificationMetric\n",
    "from aif360.algorithms.preprocessing import Reweighing\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Load COMPAS dataset\n",
    "dataset = CompasDataset()\n",
    "\n",
    "# Split into train and test sets\n",
    "train, test = dataset.split([0.7], shuffle=True)\n",
    "\n",
    "# Bias metrics before mitigation\n",
    "metric_orig = BinaryLabelDatasetMetric(train, unprivileged_groups=[{'race': 1}], privileged_groups=[{'race': 0}])\n",
    "print(\"Original disparate impact:\", metric_orig.disparate_impact())\n",
    "\n",
    "# Apply reweighing\n",
    "RW = Reweighing(unprivileged_groups=[{'race': 1}], privileged_groups=[{'race': 0}])\n",
    "RW.fit(train)\n",
    "train_transf = RW.transform(train)\n",
    "\n",
    "# Prepare data for classifier\n",
    "X_train = train_transf.features\n",
    "y_train = train_transf.labels.ravel()\n",
    "X_test = test.features\n",
    "y_test = test.labels.ravel()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Train model\n",
    "model = LogisticRegression()\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Predict on test set\n",
    "test_pred = test.copy()\n",
    "test_pred.labels = y_pred\n",
    "\n",
    "# Evaluate fairness post-mitigation\n",
    "metric_post = ClassificationMetric(test, test_pred,\n",
    "                                   unprivileged_groups=[{'race': 1}],\n",
    "                                   privileged_groups=[{'race': 0}])\n",
    "\n",
    "print(\"Disparate Impact (after):\", metric_post.disparate_impact())\n",
    "print(\"Statistical Parity Difference (after):\", metric_post.statistical_parity_difference())\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "\n",
    "# Plot false positive rate by race\n",
    "races = test_pred.protected_attributes[:, 0]\n",
    "df = pd.DataFrame({\n",
    "    'race': races,\n",
    "    'true': test.labels.ravel(),\n",
    "    'pred': y_pred\n",
    "})\n",
    "df['false_positive'] = (df['pred'] == 1) & (df['true'] == 0)\n",
    "df['race_label'] = df['race'].map({0.0: 'Caucasian', 1.0: 'African-American'})\n",
    "\n",
    "sns.barplot(data=df, x='race_label', y='false_positive', estimator=np.mean)\n",
    "plt.title('False Positive Rate by Race')\n",
    "plt.ylabel('False Positive Rate')\n",
    "plt.xlabel('Race')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
